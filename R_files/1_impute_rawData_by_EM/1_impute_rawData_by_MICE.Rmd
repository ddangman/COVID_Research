```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # enables Knit code display
knitr::opts_chunk$set(warning = FALSE, message = FALSE) # disables Knit warning
```


```{r}
library(readr)
library(openxlsx)

# Import raw data from github
covid_url <- "https://raw.githubusercontent.com/ddangman/COVID_Research/refs/heads/main/data/dt.COVID_TCR.vjGene.p.csv"
covid_df <- read_csv(covid_url)

pt_info_url <- "https://raw.githubusercontent.com/ddangman/COVID_Research/refs/heads/main/data/dt.info_edited.xlsx"
pt_info_df <- read.xlsx(pt_info_url, sheet = 1)

healthy_url <- "https://raw.githubusercontent.com/ddangman/COVID_Research/refs/heads/main/data/dt.HD_TCR.vjGene.p.csv"
healthy_df <- read_csv(healthy_url)

# Transpose the dataset
covid_transposed <- t(covid_df)
healthy_transposed <- t(healthy_df)

# Convert to data frame
covid_transposed <- as.data.frame(covid_transposed, stringsAsFactors = FALSE)
healthy_transposed <- as.data.frame(healthy_transposed, stringsAsFactors = FALSE)

# Set first row as column names
colnames(covid_transposed) <- covid_transposed[1, ]
colnames(healthy_transposed) <- healthy_transposed[1, ]

# Remove the first row
covid_transposed <- covid_transposed[-1, ]
healthy_transposed <- healthy_transposed[-1, ]

# Remove "TRB" from column names
colnames(covid_transposed) <- gsub("TRB", "", colnames(covid_transposed))
colnames(healthy_transposed) <- gsub("TRB", "", colnames(healthy_transposed))

# Strip "TRB-Pt-" from row names
rownames(covid_transposed) <- gsub("TRB-Pt-", "", rownames(covid_transposed))

# Identify unique columns in covid_transposed
covid_unique_cols <- setdiff(colnames(covid_transposed), colnames(healthy_transposed))

# Print the result
print(covid_unique_cols)
```

Missing data approaches: \
Mean imputation can be used when the distribution of the data is normal, and the missing values are random. \
Median imputation is appropriate when the distribution of the data is skewed. \
Mode imputation is used when dealing with categorical data, where the mode represents the most common category. \

If we assume missing markers are present but below reading threshold, we can: \
Assign some arbirtrarily small value based on minimum value of each feature. \
Treat each feature as truncated distribution and use **expectation maximization** to impute most likely missing value.


```{r}
# Load necessary libraries
library(dplyr)

# Function to count normally distributed columns
count_normal_columns <- function(df) {
  normal_count <- sum(sapply(df, function(col) {
    col <- as.numeric(col)  # Convert to numeric
    col <- col[!is.na(col)]  # Remove NAs
    n <- length(col)

    if (n < 3) return(FALSE)  # Skip columns with fewer than 3 values
    if (n > 5000) {
      # Use Kolmogorov-Smirnov test for large samples
      p_value <- ks.test(col, "pnorm", mean(col), sd(col))$p.value
    } else {
      # Use Shapiro-Wilk test for smaller samples
      p_value <- shapiro.test(col)$p.value
    }

    return(p_value > 0.05)  # Returns TRUE if normally distributed
  }))

  return(normal_count)
}

# Count normally distributed columns
covid_normal_count <- count_normal_columns(covid_transposed)
healthy_normal_count <- count_normal_columns(healthy_transposed)

# Print results
cat("Number of normally distributed columns in COVID data set:", covid_normal_count, "\n")
cat("Number of normally distributed columns in Healthy Donors:", healthy_normal_count, "\n")

```

```{r}
# Convert all values to numeric (ignoring column names)
covid_values <- as.numeric(unlist(covid_transposed))
healthy_values <- as.numeric(unlist(healthy_transposed))

# Find the minimum value in each dataset
min_covid <- min(covid_values, na.rm = TRUE)
min_healthy <- min(healthy_values, na.rm = TRUE)

# Print the results
cat("Smallest value in COVID data set:", min_covid, "\n")
cat("Smallest value in Healthy Donor:", min_healthy, "\n")
```

```{r}
# Function to extract the smallest value from each column
get_min_values <- function(df) {
  min_values <- sapply(df, function(col) {
    col <- as.numeric(col)  # Convert to numeric
    col <- col[!is.na(col)]  # Remove NAs
    if (length(col) == 0) return(NA)  # Handle empty columns
    return(min(col))  # Get the minimum value
  })
  return(min_values[!is.na(min_values)])  # Remove NA values
}

# Get smallest values from each column
covid_min_values <- get_min_values(covid_transposed)
healthy_min_values <- get_min_values(healthy_transposed)

# Compute average of the minimum values
avg_covid_min <- mean(covid_min_values, na.rm = TRUE)
avg_healthy_min <- mean(healthy_min_values, na.rm = TRUE)

# Print results
cat("Average of smallest values in COVID data set:", avg_covid_min, "\n")
cat("Average of smallest values in Healthy:", avg_healthy_min, "\n")

```


impute using MICE on entire data set \
While both "MICE" (Multiple Imputation by Chained Equations) and "Expectation Maximization (EM)" are used to handle missing data in statistics, the key difference is that MICE directly imputes missing values by filling them in with plausible estimates, whereas EM estimates model parameters based on the likelihood function without explicitly filling in the missing data points; essentially, MICE creates multiple complete datasets while EM works on the incomplete dataset itself to find the best parameters. 
```{r}
# Load necessary library
library(mice)

# Function to impute missing values while skipping error-causing columns
impute_missing_values <- function(df) {
  df <- as.data.frame(lapply(df, as.numeric))  # Ensure numeric format

  # Identify columns that will cause errors (fully NA or constant)
  problematic_cols <- sapply(df, function(col) {
    col <- col[!is.na(col)]  # Remove NA values
    return(length(unique(col)) < 2)  # If fewer than 2 unique values, it's problematic
  })

  # Subset dataframe to exclude problematic columns
  df_valid <- df[, !problematic_cols]

  # Run imputation only on valid columns
  imputed_data <- mice(df_valid, method = "pmm", m = 1, maxit = 50, seed = 123)

  # Merge imputed values back into original dataframe (keeping skipped columns unchanged)
  df[, !problematic_cols] <- complete(imputed_data)

  return(df)  # Return the completed dataset
}

# Apply EM-based imputation while skipping error-prone columns
covid_imputed <- impute_missing_values(covid_transposed)
healthy_imputed <- impute_missing_values(healthy_transposed)
```


save as single data frame
```{r}
saveRDS(covid_imputed, "covid_MICE_imputed.rds")
saveRDS(healthy_imputed, "healthy_MICE_imputed.rds")
```


If we assume NA values are below detection threshold, \
we want to see how this assumption compares to MICE imputations \
we can replace NA with minimum value of each column and subtract imputed data set
```{r}
# Function to replace NA with the smallest value in the column
replace_na_with_min <- function(df) {
  df <- as.data.frame(lapply(df, function(col) {
    col <- as.numeric(col)  # Ensure numeric format
    min_val <- min(col, na.rm = TRUE)  # Find the smallest value (ignoring NA)
    col[is.na(col)] <- min_val  # Replace NA with the smallest value
    return(col)
  }))
  return(df)
}

# Apply NA replacement on imputed datasets
covid_min <- replace_na_with_min(covid_transposed)
healthy_min <- replace_na_with_min(healthy_transposed)

# Subtract while handling NA values
covid_diff <- as.data.frame(mapply(function(x, y) ifelse(is.na(x) | is.na(y), x, x - y), covid_min, covid_imputed))
healthy_diff <- as.data.frame(mapply(function(x, y) ifelse(is.na(x) | is.na(y), x, x - y), healthy_min, healthy_imputed))
```

We see most of the difference is negative, which is the result we want if we assume NA values are below detection threshold \
Some of the values are positive such as those in column "V10.2_J2.4". \
These values were skipped due to NA cannot be subtracted from a number \
Unfortunately, this is not one of the columns present in COVID data set that is missing from Healthy Donor data set as that would give us two reasons to drop that column. \


Find positive difference where data was not imputed. \
```{r}
# Create a logical matrix where:
# - TRUE means the value in covid_diff is positive AND the corresponding value in covid_transposed is NA
imputed_above_col_min_COVID <- covid_diff > 0 & is.na(covid_imputed)
intersect1 <- sum(imputed_above_col_min_COVID)
print(intersect1)

imputed_above_col_min_HD <- healthy_diff > 0 & is.na(healthy_imputed)
intersect2 <- sum(imputed_above_col_min_HD)
print(intersect2)
```

If difference value is positive, then we have an imputed value that is potentially greater than the column's minimum value \
If that value corresponds NA imputed, then MICE algorithm failed to impute due to lack of data, which explains the positive value.
```{r}
cat(intersect1, "==", sum(covid_diff > 0), "==", sum(is.na(covid_imputed)), "\n")
cat(intersect2, "==", sum(healthy_diff > 0), "==", sum(is.na(healthy_imputed)))
```

Count of values not imputed matches count of positive difference. This also matches intersection. \
count(intersect_AB) == count(A) == count(B)

Check that all NA values are accounted for
```{r}
NA_count1 <- sum(is.na(covid_transposed))
lt_min1 <- sum(covid_diff < 0) # COVID imputed less than column's minimum
no_impute1 <- sum(is.na(covid_imputed)) # no MICE imputed COVID
cat(NA_count1, "==", lt_min1+no_impute1, "=", lt_min1, "+", no_impute1, "\n")

NA_count2 <- sum(is.na(healthy_transposed))
lt_min2 <- sum(healthy_diff < 0) # HD imputed less than column's minimum
no_impute2 <- sum(is.na(healthy_imputed)) # no MICE impute Healthy Donor
cat(NA_count2, "==", lt_min2+no_impute2, "=", lt_min2, "+", no_impute2)
```

How many were imputed to be the column's minimum?
```{r}
imputed_as_min1 <- sum(covid_diff == 0 & is.na(covid_transposed))
imputed_as_min1

imputed_as_min2 <- sum(healthy_diff == 0 & is.na(healthy_transposed))
imputed_as_min2
```

Are all NA values accounted for now?
```{r}
cat(NA_count1, "==", lt_min1+no_impute1+imputed_as_min1, "=", lt_min1, "+", no_impute1, "+", imputed_as_min1,"\n")
cat(NA_count2, "==", lt_min2+no_impute2+imputed_as_min2, "=", lt_min2, "+", no_impute2, "+", imputed_as_min2)
```

Should we leave values imputed to be the column's minimum as is or nudge them lower? \
If so, how much should we nudge them below our unknown measurable threshold we are assuming exists?
